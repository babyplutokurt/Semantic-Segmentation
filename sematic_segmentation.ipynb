{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sematic-segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SXesjpq4FGV"
      },
      "source": [
        "### **Semantic Segmentation using Cityscapes Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5z3ACzsYjgu"
      },
      "source": [
        "from os.path import join, isdir\n",
        "from os import listdir, rmdir\n",
        "from shutil import move, rmtree, make_archive\n",
        "\n",
        "COLAB_DIR = '/content/'\n",
        "GT_DIR = COLAB_DIR + 'gtFine/gtFine/'\n",
        "IMG_DIR = COLAB_DIR + 'leftImg/leftImg8bit/'\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, ReLU, LeakyReLU, Add\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D, GlobalAveragePooling2D"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbEX3aAHHtWd"
      },
      "source": [
        "#### Importing Cityscapes Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwDxzhDa4NXs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf14e29a-3704-47db-d332-3077cdb71db2"
      },
      "source": [
        "# !pip install cityscapesscripts\n",
        "from cityscapesscripts.download import downloader\n",
        "\n",
        "# registration on https://www.cityscapes-dataset.com/\n",
        "session = downloader.login()\n",
        "downloader.get_available_packages(session=session)\n",
        "\n",
        "# data for semantic segmentation task\n",
        "print('Downloading gtFine and leftImg8bit packages ...\\n')\n",
        "package_list =['gtFine_trainvaltest.zip', 'leftImg8bit_trainvaltest.zip']\n",
        "downloader.download_packages(session=session, package_names=package_list, destination_path=COLAB_DIR)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading gtFine and leftImg8bit packages ...\n",
            "\n",
            "Downloading cityscapes package 'gtFine_trainvaltest.zip' to '/content/gtFine_trainvaltest.zip'\n",
            "Downloading cityscapes package 'leftImg8bit_trainvaltest.zip' to '/content/leftImg8bit_trainvaltest.zip'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJJ4e6XB_7sx"
      },
      "source": [
        "!unzip -q gtFine_trainvaltest.zip -d gtFine\n",
        "!unzip -q leftImg8bit_trainvaltest.zip -d leftImg"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKTYIzHoQICe"
      },
      "source": [
        "#### Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIAJ00lWAEp2"
      },
      "source": [
        "# collapse child directories\n",
        "for parent in listdir(GT_DIR):\n",
        "    parent_dir = GT_DIR + parent\n",
        "    for child in listdir(parent_dir):\n",
        "        if isdir(join(parent_dir, child)):\n",
        "            keep = glob.glob(join(parent_dir, child) + '/*_gtFine_color.png')\n",
        "            keep = [f.split('/')[-1] for f in keep]\n",
        "            for filename in list(set(listdir(join(parent_dir, child))) & set(keep)):\n",
        "                move(join(parent_dir, child, filename), join(parent_dir, filename))\n",
        "            rmtree(join(parent_dir, child))\n",
        "\n",
        "for parent in listdir(IMG_DIR):\n",
        "    parent_dir = IMG_DIR + parent\n",
        "    for child in listdir(parent_dir):\n",
        "        if isdir(join(parent_dir, child)):\n",
        "            for filename in listdir(join(parent_dir, child)):\n",
        "                move(join(parent_dir, child, filename), join(parent_dir, filename))\n",
        "            rmtree(join(parent_dir, child))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8Q-awSAZCIp"
      },
      "source": [
        "#### Archive Processed Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fllZ1CO-W5VF"
      },
      "source": [
        "# resize and archive gtFine, leftImg\n",
        "IMG_SHAPE = 299, 299\n",
        "\n",
        "gt_train_paths = [GT_DIR+'train/' + path for path in listdir(GT_DIR+'train/')]\n",
        "gt_test_paths = [GT_DIR+'test/' + path for path in listdir(GT_DIR+'test/')]\n",
        "gt_val_paths = [GT_DIR+'val/' + path for path in listdir(GT_DIR+'val/')]\n",
        "gt_paths = gt_train_paths + gt_test_paths + gt_val_paths\n",
        "\n",
        "im_train_paths = [IMG_DIR+'train/' + path for path in listdir(IMG_DIR+'train/')]\n",
        "im_test_paths = [IMG_DIR+'test/' + path for path in listdir(IMG_DIR+'test/')]\n",
        "im_val_paths = [IMG_DIR+'val/' + path for path in listdir(IMG_DIR+'val/')]\n",
        "im_paths = im_train_paths + im_test_paths + im_val_paths\n",
        "\n",
        "def resize_image(path):\n",
        "    img = Image.open(path)\n",
        "    img.thumbnail(IMG_SHAPE)\n",
        "    out_file = join(path)\n",
        "    img.save(out_file, 'PNG')\n",
        "\n",
        "for img in gt_paths + im_paths:\n",
        "    resize_image(img)\n",
        "\n",
        "make_archive('gtFine', 'zip', GT_DIR)\n",
        "make_archive('leftImg', 'zip', IMG_DIR)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL3yJRbPv8yW"
      },
      "source": [
        "#### Load Processed Archive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38ZFkqyQxGok",
        "outputId": "2b13c88d-3827-41b1-f33a-89f23d063310"
      },
      "source": [
        "def download_if_missing(url, target, extract=True):\n",
        "    if os.path.exists(target):\n",
        "        return target\n",
        "    return tf.keras.utils.get_file(target, origin=url, extract=extract)\n",
        "\n",
        "gt_url_file = 'https://storage.googleapis.com/mcg2208/gtFine.zip'\n",
        "im_url_file = 'https://storage.googleapis.com/mcg2208/leftImg.zip'\n",
        "\n",
        "gt_file, gt_dir = join(COLAB_DIR + 'gtFine.zip'), join(COLAB_DIR + 'gtFine/')\n",
        "im_file, im_dir = join(COLAB_DIR + 'leftImg.zip'), join(COLAB_DIR + 'leftImg/')\n",
        "\n",
        "download_if_missing(gt_url_file, gt_file, extract=False)\n",
        "download_if_missing(im_url_file, im_file, extract=False)\n",
        "\n",
        "!unzip -q $gt_file -d $gt_dir\n",
        "!unzip -q $im_file -d $im_dir"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/mcg2208/gtFine.zip\n",
            "66281472/66278611 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/mcg2208/leftImg.zip\n",
            "338722816/338717519 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUY9iLaVZZHB",
        "outputId": "966a2201-9dde-405d-916b-d603770bd07a"
      },
      "source": [
        "# normalize and resize images\n",
        "IMG_SIZE = 299\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "GT_DIR = COLAB_DIR + 'gtFine/'\n",
        "IMG_DIR = COLAB_DIR + 'leftImg/'\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
        "    img /= 255.0\n",
        "    return img\n",
        "\n",
        "gt_train_paths = [GT_DIR + 'train/' + path for path in listdir(GT_DIR + 'train/')]\n",
        "gt_train_ds = tf.data.Dataset.from_tensor_slices(gt_train_paths)\n",
        "gt_train_ds = gt_train_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "print('Image Dimension:')\n",
        "for n, image in enumerate(gt_train_ds.take(2)):\n",
        "  print(n, image.shape)\n",
        "\n",
        "gt_test_paths = [GT_DIR + 'test/' + path for path in listdir(GT_DIR + 'test/')]\n",
        "gt_test_ds = tf.data.Dataset.from_tensor_slices(gt_test_paths)\n",
        "gt_test_ds = gt_test_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "gt_val_paths = [GT_DIR + 'val/' + path for path in listdir(GT_DIR + 'val/')]\n",
        "gt_val_ds = tf.data.Dataset.from_tensor_slices(gt_val_paths)\n",
        "gt_val_ds = gt_val_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "im_train_paths = [IMG_DIR + 'train/' + path for path in listdir(IMG_DIR + 'train/')]\n",
        "im_train_ds = tf.data.Dataset.from_tensor_slices(im_train_paths)\n",
        "im_train_ds = im_train_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "im_test_paths = [IMG_DIR + 'test/' + path for path in listdir(IMG_DIR + 'test/')]\n",
        "im_test_ds = tf.data.Dataset.from_tensor_slices(im_test_paths)\n",
        "im_test_ds = im_test_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "im_val_paths = [IMG_DIR + 'val/' + path for path in listdir(IMG_DIR + 'val/')]\n",
        "im_val_ds = tf.data.Dataset.from_tensor_slices(im_val_paths)\n",
        "im_val_ds = im_val_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image Dimension:\n",
            "0 (299, 299, 3)\n",
            "1 (299, 299, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrubOeBaS5eV"
      },
      "source": [
        "def conv_block(X,filters,block):\n",
        "    # resiudal block with dilated convolutions\n",
        "    # add skip connection at last after doing convoluion operation to input X\n",
        "    \n",
        "    b = 'block_'+str(block)+'_'\n",
        "    f1,f2,f3 = filters\n",
        "    X_skip = X\n",
        "    # block_a\n",
        "    X = Conv2D(filters=f1,kernel_size=(1,1),dilation_rate=(1,1),\n",
        "               padding='same',kernel_initializer='he_normal',name=b+'a')(X)\n",
        "    X = BatchNormalization(name=b+'batch_norm_a')(X)\n",
        "    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_a')(X)\n",
        "    # block_b\n",
        "    X = Conv2D(filters=f2,kernel_size=(3,3),dilation_rate=(2,2),\n",
        "               padding='same',kernel_initializer='he_normal',name=b+'b')(X)\n",
        "    X = BatchNormalization(name=b+'batch_norm_b')(X)\n",
        "    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_b')(X)\n",
        "    # block_c\n",
        "    X = Conv2D(filters=f3,kernel_size=(1,1),dilation_rate=(1,1),\n",
        "               padding='same',kernel_initializer='he_normal',name=b+'c')(X)\n",
        "    X = BatchNormalization(name=b+'batch_norm_c')(X)\n",
        "    # skip_conv\n",
        "    X_skip = Conv2D(filters=f3,kernel_size=(3,3),padding='same',name=b+'skip_conv')(X_skip)\n",
        "    X_skip = BatchNormalization(name=b+'batch_norm_skip_conv')(X_skip)\n",
        "    # block_c + skip_conv\n",
        "    X = Add(name=b+'add')([X,X_skip])\n",
        "    X = ReLU(name=b+'relu')(X)\n",
        "    return X\n",
        "    \n",
        "def base_feature_maps(input_layer):\n",
        "    # base covolution module to get input image feature maps \n",
        "    \n",
        "    # block_1\n",
        "    base = conv_block(input_layer,[32,32,64],'1')\n",
        "    # block_2\n",
        "    base = conv_block(base,[64,64,128],'2')\n",
        "    # block_3\n",
        "    base = conv_block(base,[128,128,256],'3')\n",
        "    return base\n",
        "\n",
        "def pyramid_feature_maps(input_layer):\n",
        "    # pyramid pooling module\n",
        "    \n",
        "    base = base_feature_maps(input_layer)\n",
        "    # red\n",
        "    red = GlobalAveragePooling2D(name='red_pool')(base)\n",
        "    red = tf.keras.layers.Reshape((1,1,256))(red)\n",
        "    red = Conv2D(filters=64,kernel_size=(1,1),name='red_1_by_1')(red)\n",
        "    red = UpSampling2D(size=256,interpolation='bilinear',name='red_upsampling')(red)\n",
        "    red = tf.image.resize(red, [IMG_SIZE, IMG_SIZE])\n",
        "    # yellow\n",
        "    yellow = AveragePooling2D(pool_size=(2,2),name='yellow_pool')(base)\n",
        "    yellow = Conv2D(filters=64,kernel_size=(1,1),name='yellow_1_by_1')(yellow)\n",
        "    yellow = UpSampling2D(size=2,interpolation='bilinear',name='yellow_upsampling')(yellow)\n",
        "    yellow = tf.image.resize(yellow, [IMG_SIZE, IMG_SIZE])\n",
        "    # blue\n",
        "    blue = AveragePooling2D(pool_size=(4,4),name='blue_pool')(base)\n",
        "    blue = Conv2D(filters=64,kernel_size=(1,1),name='blue_1_by_1')(blue)\n",
        "    blue = UpSampling2D(size=4,interpolation='bilinear',name='blue_upsampling')(blue)\n",
        "    blue = tf.image.resize(blue, [IMG_SIZE, IMG_SIZE])\n",
        "    # green\n",
        "    green = AveragePooling2D(pool_size=(8,8),name='green_pool')(base)\n",
        "    green = Conv2D(filters=64,kernel_size=(1,1),name='green_1_by_1')(green)\n",
        "    green = UpSampling2D(size=8,interpolation='bilinear',name='green_upsampling')(green)\n",
        "    green = tf.image.resize(green, [IMG_SIZE, IMG_SIZE])\n",
        "    # base + red + yellow + blue + green\n",
        "    return tf.keras.layers.concatenate([base,red,yellow,blue,green])\n",
        "\n",
        "def last_conv_module(input_layer):\n",
        "    X = pyramid_feature_maps(input_layer)\n",
        "    X = Conv2D(filters=3,kernel_size=3,padding='same',name='last_conv_3_by_3')(X)\n",
        "    X = BatchNormalization(name='last_conv_3_by_3_batch_norm')(X)\n",
        "    X = Activation('sigmoid',name='last_conv_relu')(X)\n",
        "    # X = tf.keras.layers.Flatten(name='last_conv_flatten')(X)\n",
        "    return X"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxRmuAR1g2cV"
      },
      "source": [
        "input_shape = list(im_train_ds.take(1))[0].shape\n",
        "input_layer = tf.keras.Input(shape=input_shape, name='input')\n",
        "output_layer = last_conv_module(input_layer)\n",
        "\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaDZBH13usJH",
        "outputId": "93091e89-05ac-420d-82c1-0217a91c72c5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block_1_a (Conv2D)              (None, 299, 299, 32) 128         input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block_1_batch_norm_a (BatchNorm (None, 299, 299, 32) 128         block_1_a[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "block_1_leakyrelu_a (LeakyReLU) (None, 299, 299, 32) 0           block_1_batch_norm_a[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_1_b (Conv2D)              (None, 299, 299, 32) 9248        block_1_leakyrelu_a[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_1_batch_norm_b (BatchNorm (None, 299, 299, 32) 128         block_1_b[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "block_1_leakyrelu_b (LeakyReLU) (None, 299, 299, 32) 0           block_1_batch_norm_b[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_1_c (Conv2D)              (None, 299, 299, 64) 2112        block_1_leakyrelu_b[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_1_skip_conv (Conv2D)      (None, 299, 299, 64) 1792        input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block_1_batch_norm_c (BatchNorm (None, 299, 299, 64) 256         block_1_c[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "block_1_batch_norm_skip_conv (B (None, 299, 299, 64) 256         block_1_skip_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_1_add (Add)               (None, 299, 299, 64) 0           block_1_batch_norm_c[0][0]       \n",
            "                                                                 block_1_batch_norm_skip_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "block_1_relu (ReLU)             (None, 299, 299, 64) 0           block_1_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_2_a (Conv2D)              (None, 299, 299, 64) 4160        block_1_relu[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_2_batch_norm_a (BatchNorm (None, 299, 299, 64) 256         block_2_a[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "block_2_leakyrelu_a (LeakyReLU) (None, 299, 299, 64) 0           block_2_batch_norm_a[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_2_b (Conv2D)              (None, 299, 299, 64) 36928       block_2_leakyrelu_a[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_2_batch_norm_b (BatchNorm (None, 299, 299, 64) 256         block_2_b[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "block_2_leakyrelu_b (LeakyReLU) (None, 299, 299, 64) 0           block_2_batch_norm_b[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_2_c (Conv2D)              (None, 299, 299, 128 8320        block_2_leakyrelu_b[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_2_skip_conv (Conv2D)      (None, 299, 299, 128 73856       block_1_relu[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_2_batch_norm_c (BatchNorm (None, 299, 299, 128 512         block_2_c[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "block_2_batch_norm_skip_conv (B (None, 299, 299, 128 512         block_2_skip_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_2_add (Add)               (None, 299, 299, 128 0           block_2_batch_norm_c[0][0]       \n",
            "                                                                 block_2_batch_norm_skip_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "block_2_relu (ReLU)             (None, 299, 299, 128 0           block_2_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block_3_a (Conv2D)              (None, 299, 299, 128 16512       block_2_relu[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_3_batch_norm_a (BatchNorm (None, 299, 299, 128 512         block_3_a[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "block_3_leakyrelu_a (LeakyReLU) (None, 299, 299, 128 0           block_3_batch_norm_a[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_3_b (Conv2D)              (None, 299, 299, 128 147584      block_3_leakyrelu_a[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_3_batch_norm_b (BatchNorm (None, 299, 299, 128 512         block_3_b[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "block_3_leakyrelu_b (LeakyReLU) (None, 299, 299, 128 0           block_3_batch_norm_b[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block_3_c (Conv2D)              (None, 299, 299, 256 33024       block_3_leakyrelu_b[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block_3_skip_conv (Conv2D)      (None, 299, 299, 256 295168      block_2_relu[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block_3_batch_norm_c (BatchNorm (None, 299, 299, 256 1024        block_3_c[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "block_3_batch_norm_skip_conv (B (None, 299, 299, 256 1024        block_3_skip_conv[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block_3_add (Add)               (None, 299, 299, 256 0           block_3_batch_norm_c[0][0]       \n",
            "                                                                 block_3_batch_norm_skip_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "block_3_relu (ReLU)             (None, 299, 299, 256 0           block_3_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "red_pool (GlobalAveragePooling2 (None, 256)          0           block_3_relu[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 1, 1, 256)    0           red_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "yellow_pool (AveragePooling2D)  (None, 149, 149, 256 0           block_3_relu[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "blue_pool (AveragePooling2D)    (None, 74, 74, 256)  0           block_3_relu[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "green_pool (AveragePooling2D)   (None, 37, 37, 256)  0           block_3_relu[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "red_1_by_1 (Conv2D)             (None, 1, 1, 64)     16448       reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "yellow_1_by_1 (Conv2D)          (None, 149, 149, 64) 16448       yellow_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "blue_1_by_1 (Conv2D)            (None, 74, 74, 64)   16448       blue_pool[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "green_1_by_1 (Conv2D)           (None, 37, 37, 64)   16448       green_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "red_upsampling (UpSampling2D)   (None, 256, 256, 64) 0           red_1_by_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "yellow_upsampling (UpSampling2D (None, 298, 298, 64) 0           yellow_1_by_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "blue_upsampling (UpSampling2D)  (None, 296, 296, 64) 0           blue_1_by_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "green_upsampling (UpSampling2D) (None, 296, 296, 64) 0           green_1_by_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ResizeBilinear (Ten [(None, 299, 299, 64 0           red_upsampling[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ResizeBilinear_1 (T [(None, 299, 299, 64 0           yellow_upsampling[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ResizeBilinear_2 (T [(None, 299, 299, 64 0           blue_upsampling[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ResizeBilinear_3 (T [(None, 299, 299, 64 0           green_upsampling[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 299, 299, 512 0           block_3_relu[0][0]               \n",
            "                                                                 tf_op_layer_ResizeBilinear[0][0] \n",
            "                                                                 tf_op_layer_ResizeBilinear_1[0][0\n",
            "                                                                 tf_op_layer_ResizeBilinear_2[0][0\n",
            "                                                                 tf_op_layer_ResizeBilinear_3[0][0\n",
            "__________________________________________________________________________________________________\n",
            "last_conv_3_by_3 (Conv2D)       (None, 299, 299, 3)  13827       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "last_conv_3_by_3_batch_norm (Ba (None, 299, 299, 3)  12          last_conv_3_by_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "last_conv_relu (Activation)     (None, 299, 299, 3)  0           last_conv_3_by_3_batch_norm[0][0]\n",
            "==================================================================================================\n",
            "Total params: 713,839\n",
            "Trainable params: 711,145\n",
            "Non-trainable params: 2,694\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f-I0DmffwFS"
      },
      "source": [
        "train_ds = tf.data.Dataset.zip((im_train_ds, gt_train_ds))\n",
        "val_ds = tf.data.Dataset.zip((im_val_ds, gt_val_ds))\n",
        "\n",
        "train_ds = train_ds.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=10, steps_per_epoch=5, verbose=1, batch_size=32)"
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}